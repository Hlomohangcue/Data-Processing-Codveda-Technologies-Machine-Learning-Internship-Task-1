{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55796341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 1: Data Preprocessing for Machine Learning\n",
    "Codveda Technologies - Machine Learning Internship\n",
    "Dataset: Churn Prediction Data (churn-bigml-80.csv)\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: September 29, 2025\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010cd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c83e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TASK 1: DATA PREPROCESSING FOR MACHINE LEARNING\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"TASK 1: DATA PREPROCESSING FOR MACHINE LEARNING\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2ba17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 1] Loading Dataset...\n",
      "âœ“ Dataset loaded successfully!\n",
      "  Shape: 2666 rows Ã— 20 columns\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 1: LOAD THE DATASET\n",
    "# ==============================================================================\n",
    "print(\"\\n[STEP 1] Loading Dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv('churn-bigml-80.csv')\n",
    "    print(f\"âœ“ Dataset loaded successfully!\")\n",
    "    print(f\"  Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âœ— Error: File 'churn-bigml-80.csv' not found.\")\n",
    "    print(\"  Please ensure the file is in the same directory as this script.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cfd8a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 2] Exploratory Data Analysis...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "  State  Account length  Area code International plan Voice mail plan  \\\n",
      "0    KS             128        415                 No             Yes   \n",
      "1    OH             107        415                 No             Yes   \n",
      "2    NJ             137        415                 No              No   \n",
      "3    OH              84        408                Yes              No   \n",
      "4    OK              75        415                Yes              No   \n",
      "\n",
      "   Number vmail messages  Total day minutes  Total day calls  \\\n",
      "0                     25              265.1              110   \n",
      "1                     26              161.6              123   \n",
      "2                      0              243.4              114   \n",
      "3                      0              299.4               71   \n",
      "4                      0              166.7              113   \n",
      "\n",
      "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
      "0             45.07              197.4               99             16.78   \n",
      "1             27.47              195.5              103             16.62   \n",
      "2             41.38              121.2              110             10.30   \n",
      "3             50.90               61.9               88              5.26   \n",
      "4             28.34              148.3              122             12.61   \n",
      "\n",
      "   Total night minutes  Total night calls  Total night charge  \\\n",
      "0                244.7                 91               11.01   \n",
      "1                254.4                103               11.45   \n",
      "2                162.6                104                7.32   \n",
      "3                196.9                 89                8.86   \n",
      "4                186.9                121                8.41   \n",
      "\n",
      "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
      "0                10.0                 3               2.70   \n",
      "1                13.7                 3               3.70   \n",
      "2                12.2                 5               3.29   \n",
      "3                 6.6                 7               1.78   \n",
      "4                10.1                 3               2.73   \n",
      "\n",
      "   Customer service calls  Churn  \n",
      "0                       1  False  \n",
      "1                       1  False  \n",
      "2                       0  False  \n",
      "3                       2  False  \n",
      "4                       3  False  \n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 2: EXPLORATORY DATA ANALYSIS\n",
    "# ==============================================================================\n",
    "print(\"\\n[STEP 2] Exploratory Data Analysis...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47985126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Summary:\n",
      "       Account length    Area code  Number vmail messages  Total day minutes  \\\n",
      "count     2666.000000  2666.000000            2666.000000         2666.00000   \n",
      "mean       100.620405   437.438860               8.021755          179.48162   \n",
      "std         39.563974    42.521018              13.612277           54.21035   \n",
      "min          1.000000   408.000000               0.000000            0.00000   \n",
      "25%         73.000000   408.000000               0.000000          143.40000   \n",
      "50%        100.000000   415.000000               0.000000          179.95000   \n",
      "75%        127.000000   510.000000              19.000000          215.90000   \n",
      "max        243.000000   510.000000              50.000000          350.80000   \n",
      "\n",
      "       Total day calls  Total day charge  Total eve minutes  Total eve calls  \\\n",
      "count      2666.000000       2666.000000        2666.000000      2666.000000   \n",
      "mean        100.310203         30.512404         200.386159       100.023631   \n",
      "std          19.988162          9.215733          50.951515        20.161445   \n",
      "min           0.000000          0.000000           0.000000         0.000000   \n",
      "25%          87.000000         24.380000         165.300000        87.000000   \n",
      "50%         101.000000         30.590000         200.900000       100.000000   \n",
      "75%         114.000000         36.700000         235.100000       114.000000   \n",
      "max         160.000000         59.640000         363.700000       170.000000   \n",
      "\n",
      "       Total eve charge  Total night minutes  Total night calls  \\\n",
      "count       2666.000000          2666.000000        2666.000000   \n",
      "mean          17.033072           201.168942         100.106152   \n",
      "std            4.330864            50.780323          19.418459   \n",
      "min            0.000000            43.700000          33.000000   \n",
      "25%           14.050000           166.925000          87.000000   \n",
      "50%           17.080000           201.150000         100.000000   \n",
      "75%           19.980000           236.475000         113.000000   \n",
      "max           30.910000           395.000000         166.000000   \n",
      "\n",
      "       Total night charge  Total intl minutes  Total intl calls  \\\n",
      "count         2666.000000         2666.000000       2666.000000   \n",
      "mean             9.052689           10.237022          4.467367   \n",
      "std              2.285120            2.788349          2.456195   \n",
      "min              1.970000            0.000000          0.000000   \n",
      "25%              7.512500            8.500000          3.000000   \n",
      "50%              9.050000           10.200000          4.000000   \n",
      "75%             10.640000           12.100000          6.000000   \n",
      "max             17.770000           20.000000         20.000000   \n",
      "\n",
      "       Total intl charge  Customer service calls  \n",
      "count        2666.000000             2666.000000  \n",
      "mean            2.764490                1.562641  \n",
      "std             0.752812                1.311236  \n",
      "min             0.000000                0.000000  \n",
      "25%             2.300000                1.000000  \n",
      "50%             2.750000                1.000000  \n",
      "75%             3.270000                2.000000  \n",
      "max             5.400000                9.000000  \n"
     ]
    }
   ],
   "source": [
    "# Display statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2fc362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2666 entries, 0 to 2665\n",
      "Data columns (total 20 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   State                   2666 non-null   object \n",
      " 1   Account length          2666 non-null   int64  \n",
      " 2   Area code               2666 non-null   int64  \n",
      " 3   International plan      2666 non-null   object \n",
      " 4   Voice mail plan         2666 non-null   object \n",
      " 5   Number vmail messages   2666 non-null   int64  \n",
      " 6   Total day minutes       2666 non-null   float64\n",
      " 7   Total day calls         2666 non-null   int64  \n",
      " 8   Total day charge        2666 non-null   float64\n",
      " 9   Total eve minutes       2666 non-null   float64\n",
      " 10  Total eve calls         2666 non-null   int64  \n",
      " 11  Total eve charge        2666 non-null   float64\n",
      " 12  Total night minutes     2666 non-null   float64\n",
      " 13  Total night calls       2666 non-null   int64  \n",
      " 14  Total night charge      2666 non-null   float64\n",
      " 15  Total intl minutes      2666 non-null   float64\n",
      " 16  Total intl calls        2666 non-null   int64  \n",
      " 17  Total intl charge       2666 non-null   float64\n",
      " 18  Customer service calls  2666 non-null   int64  \n",
      " 19  Churn                   2666 non-null   bool   \n",
      "dtypes: bool(1), float64(8), int64(8), object(3)\n",
      "memory usage: 398.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636b3d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Count:\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values Count:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c56656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Data Types:\n",
      "  Numerical columns (16): ['Account length', 'Area code', 'Number vmail messages', 'Total day minutes', 'Total day calls', 'Total day charge', 'Total eve minutes', 'Total eve calls', 'Total eve charge', 'Total night minutes', 'Total night calls', 'Total night charge', 'Total intl minutes', 'Total intl calls', 'Total intl charge', 'Customer service calls']\n",
      "  Categorical columns (4): ['State', 'International plan', 'Voice mail plan', 'Churn']\n"
     ]
    }
   ],
   "source": [
    "# Identify data types\n",
    "print(\"\\nColumn Data Types:\")\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object', 'bool']).columns.tolist()\n",
    "print(f\"  Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"  Categorical columns ({len(categorical_cols)}): {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c566cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 3] Handling Missing Data...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ No missing values found in the dataset!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 3: HANDLE MISSING DATA\n",
    "# ==============================================================================\n",
    "print(\"\\n[STEP 3] Handling Missing Data...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Check for missing values\n",
    "total_missing = df_processed.isnull().sum().sum()\n",
    "\n",
    "if total_missing > 0:\n",
    "    print(f\"Found {total_missing} missing values. Applying imputation strategies...\")\n",
    "    \n",
    "    # Strategy 1: Fill numerical columns with median\n",
    "    if len(numerical_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        df_processed[numerical_cols] = num_imputer.fit_transform(df_processed[numerical_cols])\n",
    "        print(f\"âœ“ Numerical columns: Filled with median\")\n",
    "    \n",
    "    # Strategy 2: Fill categorical columns with mode\n",
    "    if len(categorical_cols) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_processed[categorical_cols] = cat_imputer.fit_transform(df_processed[categorical_cols])\n",
    "        print(f\"âœ“ Categorical columns: Filled with most frequent value\")\n",
    "    \n",
    "    print(f\"âœ“ Missing values after imputation: {df_processed.isnull().sum().sum()}\")\n",
    "else:\n",
    "    print(\"âœ“ No missing values found in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5138f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 4] Encoding Categorical Variables...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ State: Label Encoded (High cardinality - 51 values)\n",
      "âœ“ International plan: Label Encoded (Binary) - {'No': 0, 'Yes': 1}\n",
      "âœ“ Voice mail plan: Label Encoded (Binary) - {'No': 0, 'Yes': 1}\n",
      "âœ“ Churn: Label Encoded (Binary) - {False: 0, True: 1}\n",
      "\n",
      "âœ“ All categorical variables encoded successfully!\n",
      "  Dataset shape after encoding: (2666, 20)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 4: ENCODE CATEGORICAL VARIABLES\n",
    "# ==============================================================================\n",
    "print(\"\\n[STEP 4] Encoding Categorical Variables...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Separate target variable if it exists (common names: 'Churn', 'Target', etc.)\n",
    "target_col = None\n",
    "for col in df_processed.columns:\n",
    "    if 'churn' in col.lower() or 'target' in col.lower():\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "# Create encoding mappings dictionary for reference\n",
    "encoding_mappings = {}\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    for col in categorical_cols:\n",
    "        unique_values = df_processed[col].nunique()\n",
    "        \n",
    "        # Binary columns: Use Label Encoding\n",
    "        if unique_values == 2:\n",
    "            le = LabelEncoder()\n",
    "            df_processed[col] = le.fit_transform(df_processed[col])\n",
    "            encoding_mappings[col] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "            print(f\"âœ“ {col}: Label Encoded (Binary) - {encoding_mappings[col]}\")\n",
    "        \n",
    "        # Low cardinality (3-10 unique values): Use One-Hot Encoding\n",
    "        elif unique_values <= 10:\n",
    "            # Get one-hot encoded columns\n",
    "            one_hot = pd.get_dummies(df_processed[col], prefix=col, drop_first=True)\n",
    "            # Drop original column and add one-hot encoded columns\n",
    "            df_processed = pd.concat([df_processed.drop(col, axis=1), one_hot], axis=1)\n",
    "            encoding_mappings[col] = f\"One-Hot Encoded ({unique_values} categories)\"\n",
    "            print(f\"âœ“ {col}: One-Hot Encoded ({unique_values} unique values)\")\n",
    "        \n",
    "        # High cardinality: Use Label Encoding (to avoid dimension explosion)\n",
    "        else:\n",
    "            le = LabelEncoder()\n",
    "            df_processed[col] = le.fit_transform(df_processed[col])\n",
    "            encoding_mappings[col] = f\"Label Encoded ({unique_values} categories)\"\n",
    "            print(f\"âœ“ {col}: Label Encoded (High cardinality - {unique_values} values)\")\n",
    "    \n",
    "    print(f\"\\nâœ“ All categorical variables encoded successfully!\")\n",
    "    print(f\"  Dataset shape after encoding: {df_processed.shape}\")\n",
    "else:\n",
    "    print(\"âœ“ No categorical variables found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfef0f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 5] Normalizing/Standardizing Numerical Features...\n",
      "----------------------------------------------------------------------\n",
      "Note: Target column 'Churn' excluded from scaling\n",
      "âœ“ Standardization applied using StandardScaler (Z-score normalization)\n",
      "  Features scaled: 16 columns\n",
      "  Method: (X - mean) / standard_deviation\n",
      "\n",
      "Scaled features statistics:\n",
      "       Account length  Area code  Number vmail messages  Total day minutes  \\\n",
      "count        2666.000   2666.000               2666.000           2666.000   \n",
      "mean           -0.000     -0.000                 -0.000              0.000   \n",
      "std             1.000      1.000                  1.000              1.000   \n",
      "min            -2.518     -0.692                 -0.589             -3.311   \n",
      "25%            -0.698     -0.692                 -0.589             -0.666   \n",
      "50%            -0.016     -0.528                 -0.589              0.009   \n",
      "75%             0.667      1.707                  0.807              0.672   \n",
      "max             3.599      1.707                  3.084              3.161   \n",
      "\n",
      "       Total day calls  Total day charge  Total eve minutes  Total eve calls  \\\n",
      "count         2666.000          2666.000           2666.000         2666.000   \n",
      "mean             0.000            -0.000             -0.000            0.000   \n",
      "std              1.000             1.000              1.000            1.000   \n",
      "min             -5.019            -3.312             -3.934           -4.962   \n",
      "25%             -0.666            -0.666             -0.689           -0.646   \n",
      "50%              0.035             0.008              0.010           -0.001   \n",
      "75%              0.685             0.672              0.681            0.693   \n",
      "max              2.987             3.161              3.206            3.471   \n",
      "\n",
      "       Total eve charge  Total night minutes  Total night calls  \\\n",
      "count          2666.000             2666.000           2666.000   \n",
      "mean              0.000                0.000             -0.000   \n",
      "std               1.000                1.000              1.000   \n",
      "min              -3.934               -3.102             -3.456   \n",
      "25%              -0.689               -0.674             -0.675   \n",
      "50%               0.011               -0.000             -0.005   \n",
      "75%               0.681                0.695              0.664   \n",
      "max               3.205                3.818              3.394   \n",
      "\n",
      "       Total night charge  Total intl minutes  Total intl calls  \\\n",
      "count            2666.000            2666.000          2666.000   \n",
      "mean               -0.000              -0.000            -0.000   \n",
      "std                 1.000               1.000             1.000   \n",
      "min                -3.100              -3.672            -1.819   \n",
      "25%                -0.674              -0.623            -0.598   \n",
      "50%                -0.001              -0.013            -0.190   \n",
      "75%                 0.695               0.668             0.624   \n",
      "max                 3.816               3.502             6.325   \n",
      "\n",
      "       Total intl charge  Customer service calls  \n",
      "count           2666.000                2666.000  \n",
      "mean               0.000                   0.000  \n",
      "std                1.000                   1.000  \n",
      "min               -3.673                  -1.192  \n",
      "25%               -0.617                  -0.429  \n",
      "50%               -0.019                  -0.429  \n",
      "75%                0.672                   0.334  \n",
      "max                3.502                   5.673  \n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 5: NORMALIZE/STANDARDIZE NUMERICAL FEATURES\n",
    "# ==============================================================================\n",
    "print(\"\\n[STEP 5] Normalizing/Standardizing Numerical Features...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Get updated numerical columns (after encoding)\n",
    "numerical_cols_final = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove target column from scaling if it exists\n",
    "if target_col and target_col in numerical_cols_final:\n",
    "    numerical_cols_final.remove(target_col)\n",
    "    print(f\"Note: Target column '{target_col}' excluded from scaling\")\n",
    "\n",
    "if len(numerical_cols_final) > 0:\n",
    "    # Initialize StandardScaler (Z-score normalization: mean=0, std=1)\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit and transform numerical features\n",
    "    df_processed[numerical_cols_final] = scaler.fit_transform(df_processed[numerical_cols_final])\n",
    "    \n",
    "    print(f\"âœ“ Standardization applied using StandardScaler (Z-score normalization)\")\n",
    "    print(f\"  Features scaled: {len(numerical_cols_final)} columns\")\n",
    "    print(f\"  Method: (X - mean) / standard_deviation\")\n",
    "    print(f\"\\nScaled features statistics:\")\n",
    "    print(df_processed[numerical_cols_final].describe().round(3))\n",
    "else:\n",
    "    print(\"âœ“ No numerical features to scale!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a11f0ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 6] Splitting Dataset into Training and Testing Sets...\n",
      "----------------------------------------------------------------------\n",
      "âœ“ Target variable identified: 'Churn'\n",
      "\n",
      "âœ“ Dataset split completed!\n",
      "  Training set: 2132 samples (80.0%)\n",
      "  Testing set:  534 samples (20.0%)\n",
      "  Features: 19 columns\n",
      "\n",
      "Target distribution:\n",
      "  Training set:\n",
      "0    0.855\n",
      "1    0.145\n",
      "Name: Churn, dtype: float64\n",
      "  Testing set:\n",
      "0    0.854\n",
      "1    0.146\n",
      "Name: Churn, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 6: SPLIT DATASET INTO TRAINING AND TESTING SETS\n",
    "# ==============================================================================\n",
    "print(\"\\n[STEP 6] Splitting Dataset into Training and Testing Sets...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Identify features (X) and target (y)\n",
    "if target_col:\n",
    "    X = df_processed.drop(columns=[target_col])\n",
    "    y = df_processed[target_col]\n",
    "    print(f\"âœ“ Target variable identified: '{target_col}'\")\n",
    "else:\n",
    "    # If no clear target, use last column as target\n",
    "    X = df_processed.iloc[:, :-1]\n",
    "    y = df_processed.iloc[:, -1]\n",
    "    print(f\"âœ“ Using last column as target variable\")\n",
    "\n",
    "# Perform train-test split (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y if y.nunique() < 50 else None  # Stratify for classification\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Dataset split completed!\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"  Testing set:  {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"  Features: {X_train.shape[1]} columns\")\n",
    "\n",
    "# Display target distribution\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(f\"  Training set:\\n{y_train.value_counts(normalize=True).round(3)}\")\n",
    "print(f\"  Testing set:\\n{y_test.value_counts(normalize=True).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4cab5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP 7] Summary & Final Output...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ðŸ“Š PREPROCESSING SUMMARY:\n",
      "  âœ“ Original dataset shape: (2666, 20)\n",
      "  âœ“ Processed dataset shape: (2666, 20)\n",
      "  âœ“ Missing values handled: Yes\n",
      "  âœ“ Categorical encoding: 4 variables encoded\n",
      "  âœ“ Numerical scaling: 16 features standardized\n",
      "  âœ“ Train-test split: 80-20 split completed\n",
      "\n",
      "ðŸ’¾ EXPORTABLE DATASETS:\n",
      "  - X_train: Training features\n",
      "  - X_test: Testing features\n",
      "  - y_train: Training labels\n",
      "  - y_test: Testing labels\n",
      "\n",
      "âœ“ Preprocessed data saved as 'preprocessed_churn_data.csv'\n",
      "âœ“ Train-test splits saved as separate CSV files\n",
      "\n",
      "======================================================================\n",
      "âœ… DATA PREPROCESSING COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n",
      "\n",
      "ðŸŽ¯ Next Steps:\n",
      "  1. Use X_train and y_train to train your ML models\n",
      "  2. Evaluate model performance using X_test and y_test\n",
      "  3. Consider feature selection/engineering for optimization\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# STEP 7: SUMMARY AND EXPORT\n",
    "# ==============================================================================\n",
    "print(\"\\n[STEP 7] Summary & Final Output...\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š PREPROCESSING SUMMARY:\")\n",
    "print(f\"  âœ“ Original dataset shape: {df.shape}\")\n",
    "print(f\"  âœ“ Processed dataset shape: {df_processed.shape}\")\n",
    "print(f\"  âœ“ Missing values handled: Yes\")\n",
    "print(f\"  âœ“ Categorical encoding: {len(encoding_mappings)} variables encoded\")\n",
    "print(f\"  âœ“ Numerical scaling: {len(numerical_cols_final)} features standardized\")\n",
    "print(f\"  âœ“ Train-test split: 80-20 split completed\")\n",
    "\n",
    "print(\"\\nðŸ’¾ EXPORTABLE DATASETS:\")\n",
    "print(\"  - X_train: Training features\")\n",
    "print(\"  - X_test: Testing features\")\n",
    "print(\"  - y_train: Training labels\")\n",
    "print(\"  - y_test: Testing labels\")\n",
    "\n",
    "# Optional: Save preprocessed data\n",
    "try:\n",
    "    # Save preprocessed full dataset\n",
    "    df_processed.to_csv('preprocessed_churn_data.csv', index=False)\n",
    "    print(\"\\nâœ“ Preprocessed data saved as 'preprocessed_churn_data.csv'\")\n",
    "    \n",
    "    # Save train-test splits\n",
    "    X_train.to_csv('X_train.csv', index=False)\n",
    "    X_test.to_csv('X_test.csv', index=False)\n",
    "    y_train.to_csv('y_train.csv', index=False)\n",
    "    y_test.to_csv('y_test.csv', index=False)\n",
    "    print(\"âœ“ Train-test splits saved as separate CSV files\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nNote: Could not save files - {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… DATA PREPROCESSING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸŽ¯ Next Steps:\")\n",
    "print(\"  1. Use X_train and y_train to train your ML models\")\n",
    "print(\"  2. Evaluate model performance using X_test and y_test\")\n",
    "print(\"  3. Consider feature selection/engineering for optimization\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
